# ml-inference-api
 Streamline the process of building and deploying an inference API on AWS using Docker and Github actions.
